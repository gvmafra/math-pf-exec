{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tiktoken\n",
    "\n",
    "ignore_dirs = [\n",
    "  \"assets\",\n",
    "  \"node_modules\",\n",
    "  \"build\",\n",
    "  \"dist\",\n",
    "  \"venv\",\n",
    "  \".git\",\n",
    "  \".vscode\",\n",
    "  \"release\",\n",
    "  \".erb\",\n",
    "  \"main\",\n",
    "  \"__tests__\"\n",
    "    ]\n",
    "\n",
    "ignore_files = [\n",
    "    # \"__init__.py\",\n",
    "    \"listaDeEstagios.js\"\n",
    "]\n",
    "\n",
    "allowed_extensions = (\n",
    "    # \".py\",\n",
    "    # \".yaml\",\n",
    "    # \".json\",\n",
    "    # \".sh\",\n",
    "    # \".js\",\n",
    "    # \".jsx\",\n",
    "    \"ts\",\n",
    "    \"tsx\",\n",
    "    # \".cjs\"\n",
    "    )\n",
    "\n",
    "ignored_extensions = (\n",
    "    \".d.ts\"\n",
    ")\n",
    "\n",
    "\n",
    "print_token_counts = False\n",
    "# print_token_counts = True\n",
    "\n",
    "\n",
    "\n",
    "target_files = [\n",
    "    # \"test_handler.py\",\n",
    "    # \"app.py\",\n",
    "    # \"event.json\",\n",
    "    # \"open_ai_service.py\",\n",
    "    # \"aws_transcoder_service.py\",\n",
    "    # \"template.yaml\",\n",
    "    # \"build-and-release.yaml\",\n",
    "    # \"GridCanvas.tsx\",\n",
    "    # \"Game.tsx\",\n",
    "    # \"gameReducer.ts\",\n",
    "    # \"Cell.tsx\",\n",
    "    \"types.ts\",\n",
    "    \n",
    "]\n",
    "\n",
    "# target_files = []\n",
    "\n",
    "\n",
    "encode = tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\n",
    "count_token = lambda x: len(encode(x))\n",
    "\n",
    "def generate_tree(start_path, ignore_dirs = ignore_dirs):\n",
    "    tree = \"\"\n",
    "    for root, dirs, files in os.walk(start_path):\n",
    "        # ignore dirs\n",
    "        for ignore_dir in ignore_dirs:\n",
    "            if ignore_dir in dirs:\n",
    "                dirs.remove(ignore_dir)\n",
    "            \n",
    "        level = root.replace(start_path, '').count(os.sep)\n",
    "        indent = ' ' * 1 * (level)\n",
    "        tree += f\"{indent}{os.path.basename(root)}/\\n\"\n",
    "        sub_indent = ' ' * 1 * (level + 1)\n",
    "        for f in files:\n",
    "            tree += f\"{sub_indent}{f}\\n\"\n",
    "    return tree[:-1]\n",
    "\n",
    "def walk_files(path =  os.getcwd(), target_files=target_files, output_file = \"output.txt\", ignore_dirs = ignore_dirs, print_token_counts = True, ignore_files = ignore_files):\n",
    "    cwd = os.getcwd()\n",
    "    outputs = []\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for ignore_dir in ignore_dirs:\n",
    "            if ignore_dir in dirs:\n",
    "                dirs.remove(ignore_dir)\n",
    "\n",
    "        for file in files:\n",
    "            if file.endswith(allowed_extensions) and not file.endswith(ignored_extensions):\n",
    "                if file in ignore_files:\n",
    "                    continue\n",
    "                if target_files == [] or file in target_files:\n",
    "                    with open(os.path.join(root, file), \"r\") as infile:\n",
    "                        relative_path = f'{root.replace(cwd, \"\")}/{file}'[1:]\n",
    "\n",
    "                        data = infile.read()\n",
    "                        # data = re.sub(r'^\\s*//.*$', '', data, flags=re.MULTILINE)\n",
    "                        #  instead of just removeing lines with only comments, we remove all comments but keep chars before \n",
    "                        data = re.sub(r'//.*$', '', data, flags=re.MULTILINE)\n",
    "                        # handle python comments\n",
    "                        data = re.sub(r'#.*$', '', data, flags=re.MULTILINE)\n",
    "\n",
    "                        data = data.replace('\\n', ' ').replace(';', '; ')\n",
    "                        data = re.sub(r' +', ' ', data)\n",
    "                        data = data.strip()\n",
    "\n",
    "                        token_count = count_token(data) \n",
    "                                            \n",
    "                        output = {\n",
    "                            \"path\": relative_path,\n",
    "                            \"token_count\": token_count,\n",
    "                            \"data\": data\n",
    "                        }\n",
    "\n",
    "                        if len(data) > 0:\n",
    "                            outputs.append(output)\n",
    "\n",
    "    \n",
    "    outputs = sorted(outputs, key=lambda x: x['path'].split('.')[-1])\n",
    "    sept = '\\n\\n---\\n\\n'\n",
    "    tree = sept + generate_tree(path)\n",
    "\n",
    "    if print_token_counts:\n",
    "        out_string = sept.join([f\"{x['token_count']}\\n// {x['path']}\\n{x['data']}\" for x in outputs]) + tree\n",
    "    else:\n",
    "        out_string = sept.join([f\"// {x['path']}\\n{x['data']}\" for x in outputs]) + tree\n",
    "\n",
    "    total_token_count = count_token(out_string)\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        outfile.write(f'Total token count: {total_token_count}\\n\\n{out_string}')\n",
    "\n",
    "walk_files(print_token_counts = print_token_counts)\n",
    "os.system(\"code output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Circle_2_a\" | \"Circle_2_b\" | \"Circle_2_c\" | \"Circle_2_d\" | \"Circle_2_e\" | \"Circle_2_f\" | \"Circle_2_g\" | \"Circle_3_a\" | \"Circle_3_b\" | \"Circle_3_c\" | \"Circle_3_d\" | \"Circle_3_e\" | \"Circle_3_f\" | \"Circle_3_g\" | \"Circle_4_a\" | \"Circle_4_b\" | \"Circle_4_c\" | \"Circle_4_d\" | \"Circle_4_e\" | \"Circle_4_f\" | \"Circle_4_g\" | \"Circle_6_a\" | \"Circle_6_b\" | \"Circle_6_c\" | \"Circle_6_d\" | \"Circle_6_e\" | \"Circle_6_f\" | \"Circle_6_g\" | \"Circle_8_a\" | \"Circle_8_b\" | \"Circle_8_c\" | \"Circle_8_d\" | \"Circle_8_e\" | \"Circle_8_f\" | \"Circle_8_g\" | \"Circle_9_a\" | \"Circle_9_b\" | \"Circle_9_c\" | \"Circle_9_d\" | \"Circle_9_e\" | \"Circle_9_f\" | \"Circle_9_g\" | \"Circle_10_a\" | \"Circle_10_b\" | \"Circle_10_c\" | \"Circle_10_d\" | \"Circle_10_e\" | \"Circle_10_f\" | \"Circle_10_g\" | \"Square_2_a\" | \"Square_2_b\" | \"Square_2_c\" | \"Square_2_d\" | \"Square_2_e\" | \"Square_2_f\" | \"Square_2_g\" | \"Square_3_a\" | \"Square_3_b\" | \"Square_3_c\" | \"Square_3_d\" | \"Square_3_e\" | \"Square_3_f\" | \"Square_3_g\" | \"Square_4_a\" | \"Square_4_b\" | \"Square_4_c\" | \"Square_4_d\" | \"Square_4_e\" | \"Square_4_f\" | \"Square_4_g\" | \"Square_6_a\" | \"Square_6_b\" | \"Square_6_c\" | \"Square_6_d\" | \"Square_6_e\" | \"Square_6_f\" | \"Square_6_g\" | \"Square_8_a\" | \"Square_8_b\" | \"Square_8_c\" | \"Square_8_d\" | \"Square_8_e\" | \"Square_8_f\" | \"Square_8_g\" | \"Square_9_a\" | \"Square_9_b\" | \"Square_9_c\" | \"Square_9_d\" | \"Square_9_e\" | \"Square_9_f\" | \"Square_9_g\" | \"Square_10_a\" | \"Square_10_b\" | \"Square_10_c\" | \"Square_10_d\" | \"Square_10_e\" | \"Square_10_f\" | \"Square_10_g\" | \"Triangle_2_a\" | \"Triangle_2_b\" | \"Triangle_2_c\" | \"Triangle_2_d\" | \"Triangle_2_e\" | \"Triangle_2_f\" | \"Triangle_2_g\" | \"Triangle_3_a\" | \"Triangle_3_b\" | \"Triangle_3_c\" | \"Triangle_3_d\" | \"Triangle_3_e\" | \"Triangle_3_f\" | \"Triangle_3_g\" | \"Triangle_4_a\" | \"Triangle_4_b\" | \"Triangle_4_c\" | \"Triangle_4_d\" | \"Triangle_4_e\" | \"Triangle_4_f\" | \"Triangle_4_g\" | \"Triangle_6_a\" | \"Triangle_6_b\" | \"Triangle_6_c\" | \"Triangle_6_d\" | \"Triangle_6_e\" | \"Triangle_6_f\" | \"Triangle_6_g\" | \"Triangle_8_a\" | \"Triangle_8_b\" | \"Triangle_8_c\" | \"Triangle_8_d\" | \"Triangle_8_e\" | \"Triangle_8_f\" | \"Triangle_8_g\" | \"Triangle_9_a\" | \"Triangle_9_b\" | \"Triangle_9_c\" | \"Triangle_9_d\" | \"Triangle_9_e\" | \"Triangle_9_f\" | \"Triangle_9_g\" | \"Triangle_10_a\" | \"Triangle_10_b\" | \"Triangle_10_c\" | \"Triangle_10_d\" | \"Triangle_10_e\" | \"Triangle_10_f\" | \"Triangle_10_g\" | \"Diamond_2_a\" | \"Diamond_2_b\" | \"Diamond_2_c\" | \"Diamond_2_d\" | \"Diamond_2_e\" | \"Diamond_2_f\" | \"Diamond_2_g\" | \"Diamond_3_a\" | \"Diamond_3_b\" | \"Diamond_3_c\" | \"Diamond_3_d\" | \"Diamond_3_e\" | \"Diamond_3_f\" | \"Diamond_3_g\" | \"Diamond_4_a\" | \"Diamond_4_b\" | \"Diamond_4_c\" | \"Diamond_4_d\" | \"Diamond_4_e\" | \"Diamond_4_f\" | \"Diamond_4_g\" | \"Diamond_6_a\" | \"Diamond_6_b\" | \"Diamond_6_c\" | \"Diamond_6_d\" | \"Diamond_6_e\" | \"Diamond_6_f\" | \"Diamond_6_g\" | \"Diamond_8_a\" | \"Diamond_8_b\" | \"Diamond_8_c\" | \"Diamond_8_d\" | \"Diamond_8_e\" | \"Diamond_8_f\" | \"Diamond_8_g\" | \"Diamond_9_a\" | \"Diamond_9_b\" | \"Diamond_9_c\" | \"Diamond_9_d\" | \"Diamond_9_e\" | \"Diamond_9_f\" | \"Diamond_9_g\" | \"Diamond_10_a\" | \"Diamond_10_b\" | \"Diamond_10_c\" | \"Diamond_10_d\" | \"Diamond_10_e\" | \"Diamond_10_f\" | \"Diamond_10_g\" | \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def generate_strings(letters, numbers, shapes):\n",
    "    # Capitalize the first letter of each shape\n",
    "    shapes = [shape.capitalize() for shape in shapes]\n",
    "    # Generate all possible combinations of shapes, numbers, and letters\n",
    "    combinations = list(itertools.product(shapes, numbers, letters))\n",
    "    # Format the combinations into strings and return the result\n",
    "    return [f'{shape}_{number}_{letter}' for shape, number, letter in combinations]\n",
    "\n",
    "letters = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"]\n",
    "numbers = [2, 3, 4, 6, 8, 9, 10]\n",
    "shapes = [\"circle\", \"square\", \"triangle\", \"diamond\"]\n",
    "\n",
    "\n",
    "all_strings = generate_strings(letters, numbers, shapes)\n",
    "final_string = \"\"\n",
    "for string in all_strings:\n",
    "    final_string += f'\"{string}\" | '\n",
    "\n",
    "print(final_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
